#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Servicio de chat contextual para an√°lisis de im√°genes.
Permite hacer preguntas sobre im√°genes ya analizadas usando YOLO + GPT-4 Vision.
"""

import logging
import json
from typing import Dict, Any, List, Optional
from datetime import datetime
from openai import OpenAI
from src.utils.config import get_openai_config

logger = logging.getLogger(__name__)

class ChatService:
    """
    Servicio que maneja conversaciones contextuales sobre im√°genes analizadas.
    Combina informaci√≥n de YOLO y GPT-4 Vision para responder preguntas espec√≠ficas.
    """
    
    def __init__(self):
        """Inicializa el servicio de chat."""
        self.config = get_openai_config()
        self.client = OpenAI(api_key=self.config["api_key"])
        self.context_storage = {}  # Almacena contextos de an√°lisis por sesi√≥n
        logger.info("Servicio de chat contextual inicializado")
    
    def store_analysis_context(self, session_id: str, analysis_results: Dict[str, Any], 
                             yolo_results: Dict[str, Any], image_filename: str, 
                             encoded_image: Optional[str] = None, image_format: str = "jpeg") -> None:
        """
        Almacena el contexto de un an√°lisis para futuras consultas.
        
        Args:
            session_id: ID √∫nico de la sesi√≥n
            analysis_results: Resultados del an√°lisis geogr√°fico
            yolo_results: Resultados de detecci√≥n YOLO
            image_filename: Nombre del archivo de imagen
            encoded_image: Imagen codificada en base64 para an√°lisis visual espec√≠fico
            image_format: Formato de la imagen (jpeg, png, etc.)
        """
        self.context_storage[session_id] = {
            "timestamp": datetime.now().isoformat(),
            "image_filename": image_filename,
            "geographic_analysis": analysis_results,
            "yolo_detection": yolo_results,
            "encoded_image": encoded_image,
            "image_format": image_format,
            "chat_history": []
        }
        logger.info(f"Contexto almacenado para sesi√≥n: {session_id}")
    
    def ask_question(self, session_id: str, question: str) -> Dict[str, Any]:
        """
        Procesa una pregunta sobre la imagen analizada.
        
        Args:
            session_id: ID de la sesi√≥n
            question: Pregunta del usuario
            
        Returns:
            Respuesta del chat con contexto
        """
        try:
            # Verificar si existe contexto para esta sesi√≥n
            if session_id not in self.context_storage:
                return {
                    "error": "No hay contexto de an√°lisis disponible para esta sesi√≥n",
                    "response": "Por favor, analiza una imagen primero antes de hacer preguntas.",
                    "status": "error"
                }
            
            context = self.context_storage[session_id]
            
            # Detectar si es una pregunta visual espec√≠fica
            if self._is_visual_question(question) and context.get("encoded_image"):
                logger.info(f"Pregunta visual detectada: {question}")
                return self._handle_visual_question(session_id, question, context)
            
            # Construir prompt contextual para preguntas est√°ndar
            system_prompt = self._build_chat_system_prompt(context)
            user_prompt = self._build_chat_user_prompt(question, context)
            
            # Crear conversaci√≥n con historial
            messages = [
                {"role": "system", "content": system_prompt}
            ]
            
            # Agregar historial de chat
            for chat_entry in context["chat_history"]:
                messages.append({"role": "user", "content": chat_entry["question"]})
                messages.append({"role": "assistant", "content": chat_entry["response"]})
            
            # Agregar pregunta actual
            messages.append({"role": "user", "content": user_prompt})
            
            # Obtener respuesta de GPT-4
            response = self.client.chat.completions.create(
                model=self.config["model"],
                messages=messages,  # type: ignore
                temperature=0.3,
                max_tokens=1000,
            )
            
            # Extraer respuesta
            answer = response.choices[0].message.content.strip() if response.choices[0].message.content else ""
            
            # Guardar en historial
            context["chat_history"].append({
                "question": question,
                "response": answer,
                "timestamp": datetime.now().isoformat()
            })
            
            return {
                "response": answer,
                "question": question,
                "timestamp": datetime.now().isoformat(),
                "status": "success"
            }
            
        except Exception as e:
            logger.error(f"Error en chat contextual: {str(e)}")
            return {
                "error": str(e),
                "response": "Lo siento, ocurri√≥ un error al procesar tu pregunta.",
                "status": "error"
            }
    
    def get_chat_history(self, session_id: str) -> List[Dict[str, Any]]:
        """
        Obtiene el historial de chat para una sesi√≥n.
        
        Args:
            session_id: ID de la sesi√≥n
            
        Returns:
            Lista del historial de chat
        """
        if session_id not in self.context_storage:
            return []
        
        return self.context_storage[session_id]["chat_history"]
    
    def clear_chat_history(self, session_id: str) -> bool:
        """
        Limpia el historial de chat para una sesi√≥n.
        
        Args:
            session_id: ID de la sesi√≥n
            
        Returns:
            True si se limpi√≥ exitosamente
        """
        if session_id in self.context_storage:
            self.context_storage[session_id]["chat_history"] = []
            return True
        return False
    
    def get_context_summary(self, session_id: str) -> Dict[str, Any]:
        """
        Obtiene un resumen del contexto de an√°lisis.
        
        Args:
            session_id: ID de la sesi√≥n
            
        Returns:
            Resumen del contexto
        """
        if session_id not in self.context_storage:
            return {"error": "No hay contexto disponible"}
        
        context = self.context_storage[session_id]
        geo_analysis = context["geographic_analysis"]
        yolo_detection = context["yolo_detection"]
        
        return {
            "image_filename": context["image_filename"],
            "timestamp": context["timestamp"],
            "geographic_results": {
                "country": geo_analysis.get("country", "No determinado"),
                "city": geo_analysis.get("city", "No determinado"),
                "confidence": geo_analysis.get("confidence", 0)
            },
            "yolo_results": {
                "total_objects": yolo_detection.get("total_objects", 0),
                "categories": len(yolo_detection.get("object_summary", {})),
                "top_objects": list(yolo_detection.get("object_summary", {}).keys())[:5]
            },
            "chat_messages": len(context["chat_history"])
        }
    
    def _build_chat_system_prompt(self, context: Dict[str, Any]) -> str:
        """Construye el prompt de sistema para el chat."""
        geo_analysis = context["geographic_analysis"]
        yolo_detection = context["yolo_detection"]
        
        return f"""
        Eres un asistente especializado en an√°lisis de im√°genes que puede responder preguntas 
        sobre una imagen que ya fue analizada usando YOLO 11 para detecci√≥n de objetos y 
        GPT-4 Vision para an√°lisis geogr√°fico.
        
        CONTEXTO DE LA IMAGEN ANALIZADA:
        - Archivo: {context["image_filename"]}
        - Fecha de an√°lisis: {context["timestamp"]}
        
        RESULTADOS DEL AN√ÅLISIS GEOGR√ÅFICO:
        - Pa√≠s: {geo_analysis.get("country", "No determinado")}
        - Ciudad: {geo_analysis.get("city", "No determinado")}
        - Distrito: {geo_analysis.get("district", "No determinado")}
        - Confianza: {geo_analysis.get("confidence", 0)}%
        - Evidencia: {', '.join(geo_analysis.get("supporting_evidence", []))}
        
        RESULTADOS DE DETECCI√ìN DE OBJETOS (YOLO 11):
        - Total de objetos: {yolo_detection.get("total_objects", 0)}
        - Objetos detectados: {json.dumps(yolo_detection.get("object_summary", {}), indent=2)}
        - Objetos prominentes: {json.dumps(yolo_detection.get("prominent_objects", []), indent=2)}
        - Indicadores geogr√°ficos: {json.dumps(yolo_detection.get("geographic_indicators", {}), indent=2)}
        
        INSTRUCCIONES:
        1. Responde preguntas espec√≠ficas sobre la imagen usando esta informaci√≥n
        2. Combina datos de YOLO y an√°lisis geogr√°fico cuando sea relevante
        3. S√© preciso con n√∫meros y detalles t√©cnicos
        4. Explica c√≥mo llegaste a tus conclusiones
        5. Si no tienes la informaci√≥n espec√≠fica, di que no la tienes
        6. Mant√©n las respuestas concisas pero informativas
        7. Usa emojis apropiados para hacer las respuestas m√°s amigables
        
        Puedes responder preguntas sobre:
        - Objetos detectados (tipos, cantidades, ubicaciones)
        - An√°lisis geogr√°fico (por qu√© se determin√≥ cierta ubicaci√≥n)
        - Comparaciones entre diferentes elementos
        - Detalles t√©cnicos del an√°lisis
        - Confianza en los resultados
        """
    
    def _build_chat_user_prompt(self, question: str, context: Dict[str, Any]) -> str:
        """Construye el prompt del usuario para el chat."""
        return f"""
        Pregunta sobre la imagen "{context["image_filename"]}":
        
        {question}
        
        Por favor responde usando toda la informaci√≥n disponible del an√°lisis.
        """
    
    def get_suggested_questions(self, session_id: str) -> List[str]:
        """
        Genera preguntas sugeridas basadas en el contexto.
        
        Args:
            session_id: ID de la sesi√≥n
            
        Returns:
            Lista de preguntas sugeridas
        """
        if session_id not in self.context_storage:
            return []
        
        context = self.context_storage[session_id]
        yolo_detection = context["yolo_detection"]
        geo_analysis = context["geographic_analysis"]
        
        suggestions = []
        
        # Preguntas sobre objetos detectados
        if yolo_detection.get("total_objects", 0) > 0:
            suggestions.append(f"¬øCu√°ntos objetos detect√≥ YOLO exactamente?")
            
            top_objects = list(yolo_detection.get("object_summary", {}).keys())
            if top_objects:
                suggestions.append(f"¬øPuedes describir los {top_objects[0]} que detectaste?")
        
        # Preguntas sobre an√°lisis geogr√°fico
        if geo_analysis.get("confidence", 0) > 0:
            suggestions.append(f"¬øC√≥mo determinaste que era {geo_analysis.get('country', 'este pa√≠s')}?")
            suggestions.append(f"¬øQu√© nivel de confianza tienes en el an√°lisis?")
        
        # Preguntas visuales espec√≠ficas (solo si hay imagen codificada)
        if context.get("encoded_image"):
            top_objects = list(yolo_detection.get("object_summary", {}).keys())
            if top_objects:
                # Preguntas sobre colores de objetos espec√≠ficos
                suggestions.append(f"¬øDe qu√© color son los {top_objects[0]} en la imagen?")
                suggestions.append(f"¬øC√≥mo es el aspecto de los {top_objects[0]}?")
            
            # Preguntas visuales generales
            suggestions.append("¬øQu√© colores predominan en la imagen?")
            suggestions.append("¬øPuedes describir el estado de los objetos visibles?")
        
        # Preguntas sobre la combinaci√≥n
        suggestions.append("¬øC√≥mo te ayud√≥ YOLO a mejorar el an√°lisis geogr√°fico?")
        suggestions.append("¬øQu√© elementos fueron m√°s importantes para la identificaci√≥n?")
        
        return suggestions[:6]  # M√°ximo 6 sugerencias
    
    def _is_visual_question(self, question: str) -> bool:
        """
        Detecta si una pregunta requiere an√°lisis visual espec√≠fico.
        
        Args:
            question: Pregunta del usuario
            
        Returns:
            True si requiere an√°lisis visual espec√≠fico
        """
        visual_keywords = [
            # Colores
            'color', 'colores', 'qu√© color', 'de qu√© color', 'rojo', 'azul', 'verde', 
            'amarillo', 'negro', 'blanco', 'gris', 'naranja', 'rosa', 'morado', 'violeta',
            
            # Formas y caracter√≠sticas f√≠sicas
            'forma', 'formas', 'aspecto', 'apariencia', 'tama√±o', 'grande', 'peque√±o',
            'alto', 'bajo', 'ancho', 'estrecho', 'redondo', 'cuadrado', 'rectangular',
            
            # Detalles espec√≠ficos
            'detalle', 'detalles', 'espec√≠fico', 'exacto', 'preciso', 'describe',
            'c√≥mo se ve', 'c√≥mo es', 'qu√© tal', 'marca', 'modelo', 'tipo',
            
            # Caracter√≠sticas visuales
            'brillo', 'luminoso', 'oscuro', 'claro', 'opaco', 'transparente',
            'textura', 'superficie', 'material', 'acabado', 'estado',
            
            # Patrones y elementos
            'patr√≥n', 'dise√±o', 'estilo', 'rayado', 'liso', 'rugoso',
            'nuevo', 'viejo', 'antiguo', 'moderno', 'deteriorado'
        ]
        
        question_lower = question.lower()
        return any(keyword in question_lower for keyword in visual_keywords)
    
    def _handle_visual_question(self, session_id: str, question: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """
        Maneja preguntas que requieren an√°lisis visual espec√≠fico.
        
        Args:
            session_id: ID de la sesi√≥n
            question: Pregunta del usuario
            context: Contexto de la sesi√≥n
            
        Returns:
            Respuesta del an√°lisis visual espec√≠fico
        """
        try:
            # Construir prompt para an√°lisis visual espec√≠fico
            visual_prompt = self._build_visual_analysis_prompt(question, context)
            
            # Crear mensaje para GPT-4 Vision
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": visual_prompt
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/{context['image_format']};base64,{context['encoded_image']}"
                            }
                        }
                    ]
                }
            ]
            
            # Llamar a GPT-4 Vision para an√°lisis espec√≠fico
            response = self.client.chat.completions.create(
                model=self.config["model"],
                messages=messages,  # type: ignore
                temperature=0.3,
                max_tokens=1000,
            )
            
            # Extraer respuesta
            answer = response.choices[0].message.content.strip() if response.choices[0].message.content else ""
            
            # Agregar informaci√≥n contextual
            enhanced_answer = self._enhance_visual_response(answer, context)
            
            # Guardar en historial
            context["chat_history"].append({
                "question": question,
                "response": enhanced_answer,
                "timestamp": datetime.now().isoformat(),
                "type": "visual_analysis"
            })
            
            return {
                "response": enhanced_answer,
                "question": question,
                "timestamp": datetime.now().isoformat(),
                "status": "success",
                "analysis_type": "visual_specific"
            }
            
        except Exception as e:
            logger.error(f"Error en an√°lisis visual espec√≠fico: {str(e)}")
            return {
                "error": str(e),
                "response": "Lo siento, no pude analizar los detalles visuales espec√≠ficos de la imagen.",
                "status": "error"
            }
    
    def _build_visual_analysis_prompt(self, question: str, context: Dict[str, Any]) -> str:
        """
        Construye un prompt espec√≠fico para an√°lisis visual.
        
        Args:
            question: Pregunta del usuario
            context: Contexto de la sesi√≥n
            
        Returns:
            Prompt para an√°lisis visual espec√≠fico
        """
        geo_analysis = context["geographic_analysis"]
        yolo_detection = context["yolo_detection"]
        
        return f"""
        Eres un especialista en an√°lisis visual de im√°genes. Analiza esta imagen con detalle para responder la siguiente pregunta espec√≠fica sobre caracter√≠sticas visuales.

        PREGUNTA ESPEC√çFICA: {question}

        CONTEXTO DE LA IMAGEN:
        - Archivo: {context["image_filename"]}
        - Ubicaci√≥n identificada: {geo_analysis.get("country", "No determinado")}, {geo_analysis.get("city", "No determinado")}
        - Objetos detectados por YOLO: {json.dumps(yolo_detection.get("object_summary", {}), indent=2)}

        INSTRUCCIONES PARA AN√ÅLISIS VISUAL:
        1. Observa cuidadosamente la imagen para identificar caracter√≠sticas visuales espec√≠ficas
        2. Enf√≥cate en colores, formas, texturas, materiales, estado y detalles espec√≠ficos
        3. Proporciona descripciones precisas y detalladas
        4. Si identificas marcas, modelos o caracter√≠sticas espec√≠ficas, menci√≥nalas
        5. Combina tu an√°lisis visual con el contexto geogr√°fico conocido
        6. S√© espec√≠fico con colores (no solo "azul", sino "azul oscuro", "azul cielo", etc.)
        7. Describe el estado de los objetos (nuevo, usado, deteriorado, etc.)
        8. Menciona cualquier detalle que sea relevante para la pregunta

        IMPORTANTE:
        - Responde √∫nicamente bas√°ndote en lo que puedes ver claramente en la imagen
        - Si no puedes determinar algo con certeza, dilo claramente
        - Proporciona detalles espec√≠ficos y precisos
        - Usa terminolog√≠a t√©cnica apropiada cuando sea relevante

        Responde la pregunta con el m√°ximo detalle visual posible.
        """
    
    def _enhance_visual_response(self, visual_response: str, context: Dict[str, Any]) -> str:
        """
        Mejora la respuesta visual con informaci√≥n contextual.
        
        Args:
            visual_response: Respuesta del an√°lisis visual
            context: Contexto de la sesi√≥n
            
        Returns:
            Respuesta mejorada con contexto
        """
        geo_analysis = context["geographic_analysis"]
        
        enhanced_response = f"""
        {visual_response}

        üîç **An√°lisis Visual Espec√≠fico Completado**

        Esta informaci√≥n se basa en:
        ‚Ä¢ **An√°lisis visual directo** de la imagen usando GPT-4 Vision
        ‚Ä¢ **Contexto geogr√°fico**: {geo_analysis.get('country', 'No determinado')}, {geo_analysis.get('city', 'No determinado')}
        ‚Ä¢ **Objetos detectados**: {context['yolo_detection'].get('total_objects', 0)} objetos identificados

        üí° *Tip*: Puedes hacer m√°s preguntas espec√≠ficas sobre colores, formas o caracter√≠sticas visuales de cualquier elemento en la imagen.
        """
        
        return enhanced_response.strip()